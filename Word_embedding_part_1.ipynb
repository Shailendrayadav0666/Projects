{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words: ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
     ]
    }
   ],
   "source": [
    "#Example of single document\n",
    "#without stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "#single document (',' seperates each document)\n",
    "string=['This is an example of bag of words']\n",
    "\n",
    "#this sep willl convert text into tokens\n",
    "vect1=CountVectorizer()\n",
    "\n",
    "vect1.fit_transform(string)\n",
    "print('bag of words:',vect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 5, 'is': 3, 'an': 0, 'example': 2, 'of': 4, 'bag': 1, 'words': 6}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vect=CountVectorizer()\n",
    "c_vect.fit(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text present at [[0 1 0 0 0 0 0]]\n",
      "original indexes ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
     ]
    }
   ],
   "source": [
    "string2=['lets understand bag']\n",
    "\n",
    "C_new_vect=c_vect.transform(string2)\n",
    "\n",
    "print('text present at',C_new_vect.toarray())\n",
    "\n",
    "#compare with indexes\n",
    "print(\"original indexes\",vect1.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None,\n",
      "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
      "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
      "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
      "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
      "                            'itself', ...],\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "## bag of words using stopwords(you can avoid writing extra steps to remove stopwords)\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "\n",
    "string=['this is an example of bag of words!']\n",
    "vect1=CountVectorizer(stop_words=stop_words)\n",
    "print(vect1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words: ['bag', 'example', 'words']\n",
      "vocab: {'example': 1, 'bag': 0, 'words': 2}\n"
     ]
    }
   ],
   "source": [
    "vect1.fit_transform(string)\n",
    "print(\"bag of words:\", vect1.get_feature_names())\n",
    "print(\"vocab:\",vect1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using function\n",
    "def text_matrix(message, countvect):\n",
    "    terms_doc=countvect.fit_transform(message)\n",
    "    return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below metrix is the Bag of Words approach\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>but</th>\n",
       "      <th>get</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>making</th>\n",
       "      <th>mantra</th>\n",
       "      <th>natural</th>\n",
       "      <th>only</th>\n",
       "      <th>practice</th>\n",
       "      <th>processing</th>\n",
       "      <th>progress</th>\n",
       "      <th>success</th>\n",
       "      <th>the</th>\n",
       "      <th>there</th>\n",
       "      <th>to</th>\n",
       "      <th>we</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  but  get  in  is  language  making  mantra  natural  only  practice  \\\n",
       "0    1    0    0   1   0         1       1       0        1     0         0   \n",
       "1    0    0    1   0   0         0       0       0        0     0         0   \n",
       "2    0    1    0   0   1         0       0       1        0     1         1   \n",
       "\n",
       "   processing  progress  success  the  there  to  we  will  \n",
       "0           1         1        0    0      0   0   1     0  \n",
       "1           0         0        0    0      1   0   1     1  \n",
       "2           0         0        1    1      0   1   0     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=['We are making progress in Natural Language Processing',\n",
    "         'We will get there', 'But practice is the only mantra to success']\n",
    "\n",
    "c_vect=CountVectorizer()\n",
    "print(\"below metrix is the Bag of Words approach\")\n",
    "text_matrix(message, c_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram : ['an', 'example', 'gram', 'is', 'of', 'this']\n",
      "2-gram: ['an example', 'example of', 'is an', 'of gram', 'this is']\n",
      "3-gram: ['an example of', 'example of gram', 'is an example', 'this is an']\n",
      "4-gram: ['an example of gram', 'is an example of', 'this is an example']\n"
     ]
    }
   ],
   "source": [
    "#n-grams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "string=['this is an example of n-gram!']\n",
    "\n",
    "vect1=CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "vect1.fit_transform(string)\n",
    "\n",
    "vect2=CountVectorizer(ngram_range=(2,2))\n",
    "vect2.fit_transform(string)\n",
    "\n",
    "vect3=CountVectorizer(ngram_range=(3,3))\n",
    "vect3.fit_transform(string)\n",
    "\n",
    "vect4=CountVectorizer(ngram_range=(4,4))\n",
    "vect4.fit_transform(string)\n",
    "\n",
    "print('1-gram :',vect1.get_feature_names())\n",
    "print('2-gram:',vect2.get_feature_names())\n",
    "print('3-gram:',vect3.get_feature_names())\n",
    "print('4-gram:',vect4.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log2(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>be</th>\n",
       "      <th>can</th>\n",
       "      <th>confusing</th>\n",
       "      <th>example</th>\n",
       "      <th>how</th>\n",
       "      <th>idf</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>see</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>will</th>\n",
       "      <th>works</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    an   be  can  confusing  example       how  idf   is        it       see  \\\n",
       "0  0.5  0.0  0.0        0.0      0.5  0.000000  0.0  0.5  0.000000  0.000000   \n",
       "1  0.0  0.0  0.0        0.0      0.0  0.408248  0.0  0.0  0.408248  0.408248   \n",
       "2  0.0  0.5  0.5        0.5      0.0  0.000000  0.5  0.0  0.000000  0.000000   \n",
       "\n",
       "   this        we      will     works  \n",
       "0   0.5  0.000000  0.000000  0.000000  \n",
       "1   0.0  0.408248  0.408248  0.408248  \n",
       "2   0.0  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tfid=TfidfVectorizer(smooth_idf=False)\n",
    "\n",
    "doc=['This is an example.','We will see how it works.','IDF can be confusing']\n",
    "\n",
    "doc_vector=tfid.fit_transform(doc)\n",
    "#print(tfid.get_feature_names())\n",
    "\n",
    "df=pd.DataFrame(doc_vector.todense(),columns=tfid.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covid</th>\n",
       "      <th>is</th>\n",
       "      <th>nothing</th>\n",
       "      <th>that</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.409937</td>\n",
       "      <td>0.409937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576152</td>\n",
       "      <td>0.576152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.501549</td>\n",
       "      <td>0.501549</td>\n",
       "      <td>0.704909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      covid        is   nothing      that      what\n",
       "0  0.409937  0.409937  0.000000  0.576152  0.576152\n",
       "1  0.501549  0.501549  0.704909  0.000000  0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will cal the function created earlier\n",
    "feb_message=['what is that covid','covid is nothing']\n",
    "\n",
    "tf=TfidfVectorizer()\n",
    "\n",
    "#passing same message with TF-IDF\n",
    "\n",
    "text_matrix(feb_message,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>covid</th>\n",
       "      <th>is</th>\n",
       "      <th>that</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668501</td>\n",
       "      <td>0.334251</td>\n",
       "      <td>0.469778</td>\n",
       "      <td>0.469778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.704909</td>\n",
       "      <td>0.501549</td>\n",
       "      <td>0.501549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bad     covid        is      that      what\n",
       "0  0.000000  0.668501  0.334251  0.469778  0.469778\n",
       "1  0.704909  0.501549  0.501549  0.000000  0.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importance of covid increased based on the occurence and total document\n",
    "jul_message=['what is that covid covid','covid is bad' ]\n",
    "\n",
    "text_matrix(jul_message,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer, TfidfVectorizer\n",
    "\n",
    "arr=['car was cleaned by jack', 'jack was cleaned by car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names\n",
      " ['by car', 'by jack', 'car was', 'cleaned by', 'jack was', 'was cleaned']\n",
      "array \n",
      " [[0 1 1 1 0 1]\n",
      " [1 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# if you want to take into account just term frequencies:\n",
    "vectorizer=CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "#the ngram range specifies your ngram configuration.\n",
    "\n",
    "x=vectorizer.fit_transform(arr)\n",
    "\n",
    "#testing the ngram generation:\n",
    "print('feature names\\n',vectorizer.get_feature_names())\n",
    "\n",
    "print('array \\n',x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.57615236 0.57615236 0.40993715 0.         0.40993715]\n",
      " [0.57615236 0.         0.         0.40993715 0.57615236 0.40993715]]\n"
     ]
    }
   ],
   "source": [
    "#and now testing TFIDF vectorizer:\n",
    "#you can still specify n-grams here:\n",
    "\n",
    "vectorizer=TfidfVectorizer(ngram_range=(2,2))\n",
    "x=vectorizer.fit_transform(arr)\n",
    "\n",
    "#testing the TFIDF value+ngrams:\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.40546511 1.40546511 1.         0.         1.        ]\n",
      " [1.40546511 0.         0.         1.         1.40546511 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#testing TFIDF vectorizer wthout normalization:\n",
    "#you can still specify n-grams here.\n",
    "vectorizer=TfidfVectorizer(ngram_range=(2,2),norm=None)\n",
    "\n",
    "x=vectorizer.fit_transform(arr)\n",
    "\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
