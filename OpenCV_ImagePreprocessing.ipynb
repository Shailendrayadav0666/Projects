{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets load our first image\n",
    "input_image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "cv2.imshow('hello world', input_image)\n",
    "cv2.waitKey(0)\n",
    "#this closes all open windows\n",
    "#failure to place this causes your program to hang\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "#lets take a closer look at how the image is stored\n",
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height of image: 768 pixels\n",
      "Width of image: 1024 pixels\n"
     ]
    }
   ],
   "source": [
    "#lets print each dimension ofimage\n",
    "print('Height of image:',int(input_image.shape[0]),'pixels')\n",
    "print('Width of image:',int(input_image.shape[1]),'pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To save images we edit in OpenCV\n",
    "cv2.imwrite('output.jpg',input)\n",
    "cv2.imwrite('output.png',input)\n",
    "#saves in C/users/shailendra yadav/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAYSCALING\n",
    "#In opencv, many functioons grayscale teh image before processing as it simplifies the image acting as a noise reduction and decreasing processing times as there is less info in the image now.\n",
    "#lets convert to grayscale\n",
    "\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "cv2.imshow('Original',image)\n",
    "cv2.waitKey()\n",
    "\n",
    "#we use cvtColor to convert to Grayscale\n",
    "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Grayscale',gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another faster method(0 for grayscale, 1 for color)\n",
    "img=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg',0)\n",
    "\n",
    "cv2.imshow('Grayscale',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg',0)\n",
    "height,width=image.shape\n",
    "\n",
    "#extract Sobel Edges\n",
    "sobel_x=cv2.Sobel(image, cv2.CV_64F,0,1,ksize=5)\n",
    "sobel_y=cv2.Sobel(image, cv2.CV_64F,1,0,ksize=5)\n",
    "\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel y',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "sobel_OR=cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('sobel_OR',sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian=cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian',laplacian)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translations\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg',0)\n",
    "#store the hieght and width of a image\n",
    "height, width=image.shape[:2]\n",
    "quarter_height,quarter_width=height/4,width/4\n",
    "\n",
    "#    |1 0 Tx|\n",
    "#T=  |0 1 Ty|\n",
    "\n",
    "#T is our translation matrix\n",
    "T=np.float32([[1,0,quarter_height],[0,1,quarter_width]])\n",
    "\n",
    "#we use warpAffine to transform the image using the matrix, T\n",
    "img_translation=cv2.warpAffine(image, T,(width,height))\n",
    "cv2.imshow('Translation',img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotations\n",
    "#cv2.GetRotationMatrix2D(rotation_center_x,rotation_center_y,angle of rotation,scale)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "height,width=(image.shape[:2])\n",
    "\n",
    "#divide by two to rotate the image around its center\n",
    "\n",
    "rotation_matrix=cv2.getRotationMatrix2D((width/2,height/2),90,0.75)\n",
    "rotated_image=cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "\n",
    "cv2.imshow('rotated_image',rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now do a horizontal flip.\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "flipped=cv2.flip(image,4)\n",
    "cv2.imshow('horizontal flip',flipped)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling,resizing and interpolation\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "\n",
    "\n",
    "#lets make our image 3/4 of its original size\n",
    "image_scaled=cv2.resize(image,None,fx=.75,fy=.75)\n",
    "cv2.imshow('scaling-linear interpolation',image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "#lets double the size of image\n",
    "image_double=cv2.resize(image,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('scaling-cubic-interpolation',image_double)\n",
    "cv2.waitKey()\n",
    "\n",
    "#lets skew the re-sizing by setting exact dimensions\n",
    "\n",
    "img_scaled=cv2.resize(image,(900,400),interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('scaling-skewed size',img_scaled)\n",
    "cv2.waitKey()\n",
    "           \n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE PYRAMIDS\n",
    "\n",
    "import cv2\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "\n",
    "smaller=cv2.pyrDown(image)\n",
    "larger=cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('smaller',smaller)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('larger',larger)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "height,width=image.shape[:2]\n",
    "\n",
    "#lets get the starting pixel coordinates (top left of cropping rectangle)\n",
    "start_row,start_col=int(height* .25), int(width* .25)\n",
    "\n",
    "#lets get the ending pixel coordinates(bottom right)\n",
    "end_row,end_col=int(height* .75), int(width* .75)\n",
    "\n",
    "#simply use indexing to crop out the rectangle we desire\n",
    "cropped=image[start_row:end_row,start_col:end_col]\n",
    "\n",
    "cv2.imshow('original image',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('cropped image',cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arithmetic operations\n",
    "#simple operations that allow us to add or subtract.overall effect is increasing or decreasing\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "\n",
    "#create a matrix of ones, then multiply it bya scaler of 100\n",
    "M=np.ones(image.shape, dtype='uint8')*75\n",
    "\n",
    "cv2.imshow('original',image)\n",
    "\n",
    "#we use this to add this matrix M, to our image\n",
    "#notice the increase in brightness\n",
    "added=cv2.add(image,M)\n",
    "cv2.imshow('Added',added)\n",
    "\n",
    "#likewise we can also subtract\n",
    "#notice the brightness decrease\n",
    "subtracted=cv2.subtract(image,M)\n",
    "cv2.imshow('subtracted',subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "cv2.imshow('original',image)\n",
    "\n",
    "kernel_sharpening=np.array([[-1,-1,-1],\n",
    "                            [-1,10,-1],\n",
    "                            [-1,-1,-1]])\n",
    "#applying different kernels to the input image\n",
    "sharpened=cv2.filter2D(image,-1,kernel_sharpening)\n",
    "\n",
    "cv2.imshow('image sharpening', sharpened)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blurring\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "cv2.imshow('original image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#creating our 3*3 kernel\n",
    "kernel_3x3=np.ones((3,3),np.float32)/9\n",
    "\n",
    "#we use the cv2.filter2D to convolve the kernel with an image\n",
    "blurred=cv2.filter2D(image,-1,kernel_3x3)\n",
    "cv2.imshow('3x3 kernel blurring',blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#creating our 7x7 kernel\n",
    "kernel_7x7=np.ones((7,7),np.float32)/49\n",
    "\n",
    "blurred2=cv2.filter2D(image,-1,kernel_7x7)\n",
    "cv2.imshow('7x7 kernel blurring',blurred2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#advanced blurrings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread('C:/Users/Public/Pictures/Sample Pictures/Desert.jpg')\n",
    "\n",
    "#averaging done by convolving the image with a normalized box filter\n",
    "#this takes the filter under the box and peplaces the central element\n",
    "#box size needs to add and positive\n",
    "\n",
    "blur=cv2.blur(image,(3,3))\n",
    "cv2.imshow('averaging',blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#instead of box filter, gaussian kernel\n",
    "gaussian=cv2.GaussianBlur(image,(7,7),0)\n",
    "cv2.imshow('gaussian blurring',gaussian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#takes median of all the pixels under kernel area and central element is replaceed with median value\n",
    "\n",
    "median=cv2.medianBlur(image,5)\n",
    "cv2.imshow('median blurring',median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#bilateral blurring is very effective in noise removal\n",
    "#while keeping edges sharp\n",
    "bilateral=cv2.bilateralFilter(image,9,75,75)\n",
    "cv2.imshow('bilateral blurring',bilateral)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Face and eye detection using HAAR classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#we point our OpenCV's cascadeclassifier function to where our\n",
    "#classifier (XML file format ) is stored\n",
    "\n",
    "face_classifier=cv2.CascadeClassifier('D:\\Haarcascades.xml')\n",
    "\n",
    "#load our main image convert it to grayscale\n",
    "image=cv2.imread('D:/trump/trump-1.jpg')\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#our classifier returns the ROI of the detected face as a tuple\n",
    "#it stores the top left coordinates and the bottom right cordinates\n",
    "\n",
    "faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "if faces is():\n",
    "    print(\"No faces found\")\n",
    "    \n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow('face detection',image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face and eye detection combined\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#load our main image convert it to grayscale\n",
    "img=cv2.imread('D:/trump/trump-1.jpg')\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_classifier=cv2.CascadeClassifier('D:\\Haarcascades.xml')\n",
    "eye_classifier=cv2.CascadeClassifier('D:\\haarcascade_eye.xml')\n",
    "faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "\n",
    "\n",
    "#when no faces detected, face_classifier returns and empty tuple\n",
    "\n",
    "if faces is ():\n",
    "    print('no faces found')\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray=gray[y:y+h,x:x+w]\n",
    "    roi_color=img[y:y+h,x:x+w]\n",
    "    eyes=eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0,2))\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEdestrian detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#create our body classifier\n",
    "body_classiier=cv2.CascadeClassifier('haarcascades/harcascade_fullbody.xml')\n",
    "\n",
    "#initiate video capture for video file\n",
    "cap=cv2.VideoCapture('images/walking.avi')\n",
    "\n",
    "#loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    #read firsd frame\n",
    "    ret, frame=cap.read()\n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    gray=cv2.resize(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #pass frame to our body classifier\n",
    "    \n",
    "    bodies=body_classifier.detectMultiScale(gray,1.2,3)\n",
    "    \n",
    "    #extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in bodies:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255,2))\n",
    "        cv2.imshow('pedestrians', frame)\n",
    "    \n",
    "    if cv2.waitKey(1)==13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#car detection\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#create our body classifier\n",
    "car_classifier=cv2.CascadeClassifier('Haarcascade/haarcascade_car.xml')\n",
    "\n",
    "#initiate video capture for video file\n",
    "\n",
    "cap=cv2.VideoCapture('images/cars.avi')\n",
    "\n",
    "#loop once video is successfully loaded\n",
    "\n",
    "while cap.isOpened():\n",
    "    time.sleep(.05)\n",
    "    \n",
    "    #read first frame\n",
    "    ret,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.Color_BGR2GRAY)\n",
    "    \n",
    "    #pass frame to our car classifier\n",
    "    cars=car_classifier.detectMultiScale(gray,1.4,2)\n",
    "    \n",
    "    #extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame,(x,y),(y+w,y+h),(0,255,255),2)\n",
    "        cv2.imshow('Cars',frame)\n",
    "        \n",
    "    if cv2.waitKey(1)==13: #13 is the enter key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
